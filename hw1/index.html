<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2026 Homework 1 Write-Up</h1>
		<div style="text-align: center;">Names: Patrick (Tsung-Han) Wu</div>

		<br>

		Link to webpage: <a href="https://cal-cs184-student.github.io/hw-webpages-tsunghan-wu/hw1/index.html">https://cal-cs184-student.github.io/hw-webpages-tsunghan-wu/hw1/index.html</a>
		
		<br>

		Link to GitHub repository: <a href="https://github.com/cal-cs184-student/hw1-rasterizer-tomay">https://github.com/cal-cs184-student/hw1-rasterizer-tomay</a>

<!-- 		<figure>
			<img src="lion.jpg" alt="Lion" style="width:50%"/>
			<figcaption>You can add images with captions!</figcaption>
		</figure>
 -->
		<!--
		We've already added one heading per task, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h2>Overview</h2>
		This assignment asked us to write a simple rasterizer using C++. The first two tasks focused on basic triangle rasterization with superpixel anti-aliasing. The third task was implementing three simple 2D transformation matrices. Task 4 asked us to implement barycentric coordinates, which I found tricky because we need to handle edge cases carefully; otherwise we can end up with white strips on the image. The final two tasks (Tasks 5–6) then asked us to implement texture mapping. Overall, through building these pieces end-to-end, I learned how the rasterization pipeline actually work (compared to  only reading slides), and how small implementation details (like sampling and edge handling) can noticeably affect the final rendered result.

		<h2>Task 1: Drawing Single-Color Triangles</h2>
		In this task, we implemented a basic triangle rasterization routine. In <code>void RasterizerImp::rasterize_triangle</code>, we first compute the triangle’s bounding box (a rectangle that covers the triangle). Then, for each point inside that region, we perform the three-line inside-triangle test (ref: Lecture 2 slides). We structured this logic using two helper functions: <code>is_inside_check</code> and <code>check_line</code>.

		That’s essentially it for this task. We did not implement the extra-credit optimizations, so the algorithm simply iterates over all points in the bounding box and checks whether each one is inside the triangle.

		The two requested PNG files are shown below. We can see that <code>basic/test.svg</code> renders successfully (a), but when zooming in, artifacts are visible because we are not yet using superpixels for anti-aliasing (b). We address this issue in the next task.

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="pics/task1_a.png" width="400px"/>
				  <figcaption>(a) Screenshot of Test4.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="pics/task1_b.png" width="400px"/>
				  <figcaption>(b) Screenshot of Zoomed-In Test4.</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		
		<h2>Task 2: Antialiasing by Supersampling</h2>
		We then implemented supersampling to mitigate the artifact we mentioned above. There are two main parts we need to modify in the code: (1) We need to make the buffer size from <code>H*W</code> to <code>H*W*sample_rate</code>; the modifications include the constructor (RasterizerImp), fill_pixel, set_sample_rate, set_framebuffer_target. (2) Then, the main function for supersampling is inside the <code>rasterize_triangle</code> function without a lot of tricks: it's just another for loop going through all grids inside a single pixel, and then in <code>resolve_to_framebuffer</code>, we average the value over all grids inside a single pixel so we will show blurred results there. The results of four different sample rates on the triangle is shown below. It's obvious that supersampling does mitigate the sharp boundary artifact.
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="pics/task2_sr1.png" width="400px"/>
				  <figcaption>(a) Sample Rate = 1.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="pics/task2_sr4.png" width="400px"/>
				  <figcaption>(b) Sample Rate = 4.</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="pics/task2_sr9.png" width="400px"/>
				  <figcaption>(c) Sample Rate = 9.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="pics/task2_sr16.png" width="400px"/>
				  <figcaption>(d) Sample Rate = 16.</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<h2>Task 3: Transforms</h2>
		In this task, we implemented the homogeneous 3x3 matrices for translation, rotation, and scaling, following the formulas we learned in Lecture 4. With these transforms in place, we can successfully render <code>robot.svg</code>. After that, I played with the SVG by adding a skateboard (with two wheels) using extra polygons, and then applying additional rotate/translate transforms to the arms and legs so the robot can stay balanced on the skateboard. The default robot (a) and my updated robot (b, SVG file in the <code>docs/</code> directory) are shown below:

		<div style="display: flex; flex-direction: column; align-items: center;">
		  <table style="width: 100%; text-align: center; border-collapse: collapse;">
		    <tr>
		      <td style="text-align: center;">
		        <img src="pics/task3_a.png" width="400px"/>
		        <figcaption>(a) The Default Robot.</figcaption>
		      </td>
		      <td style="text-align: center;">
		        <img src="pics/task3_b.png" width="400px"/>
		        <figcaption>(b) My Updated Robot (Raw SVG files in GitHub).</figcaption>
		      </td>
		    </tr>
		  </table>
		</div>

		<h2>Task 4: Barycentric coordinates</h2>
		To implement this task, I reused the same structure as triangle rasterization: compute a bounding box for the triangle, iterate over pixels (and sub-pixel samples when supersampling is enabled), and then determine whether each point lies inside the triangle or not. For samples that are inside, I compute barycentric weights using an area/edge-function form (solving for <code>&alpha;</code> and <code>&beta;</code>, then <code>&gamma; = 1 - &alpha; - &beta;</code>). The detailed formula is in the lecture slide. Finally, I interpolate the color by weighting the three vertex colors. It is worth mentioning that I added a small <code>eps</code> term in the barycentric denominators to reduce numerical instability near edges (e.g., when the denominator is extremely small due to floating point precision). This helps make the interpolation more stable at boundaries. Below is the requested screenshot of <code>svg/basic/test7.svg</code> with default viewing parameters and <code>sample_rate = 1</code>.


		<figure>
			<img src="pics/task4.png" alt="Lion" style="width:50%"/>
			<figcaption>Task 4's Color Palette</figcaption>
		</figure>


		<h2>Task 5: "Pixel sampling" for texture mapping</h2>
		The goal of pixel sampling is to decide which color in the source <i>texture space</i> should be assigned to each sample in the rendered image. Since mapping from screen space to texture space is generally not one-to-one, different sampling strategies can produce noticeably different visual quality, especially when the texture contains high-frequency details. In our implementation, we first reuse the barycentric-coordinate computation from Task 4 to obtain the <code>(u, v)</code> texture coordinate for each sub-sample inside <code>rasterize_textured_triangle</code>. We then  pass it to the sampling routines based on different pixel sampling mechanism in <code>texture.cpp</code>. Pixel sampling supports two modes:
		<ul>
		  <li><b>Nearest sampling</b>: map <code>(u, v)</code> to the closest texel and return that texel’s color.</li>
		  <li><b>Bilinear sampling</b>: locate the continuous texel-space position, fetch the four neighboring texels, and perform LERP along <code>x</code> and <code>y</code> to produce a smoother result.</li>
		</ul>

		An example is shown below. Here we map an example high-resolution map (2058×1036) onto a relatively small SVG. With <b>Nearest</b> sampling and <code>sample_rate = 1</code> (a), aliasing becomes severe around high-frequency features (e.g., fine text such as latitude/longitude). This can be improved either by (1) sampling from multiple nearby texels (bilinear pixel sampling) or (2) increasing the supersampling rate so each pixel averages multiple sub-samples. As a result, (b) and (c) look cleaner than (a), and (d) produces the smoothest output.
		</p>

		<div style="display: flex; flex-direction: column; align-items: center;">
		  <table style="width: 100%; text-align: center; border-collapse: collapse;">
		    <tr>
		      <td style="text-align: center;">
		        <img src="pics/task5_nearest_sr1.png" width="400px"/>
		        <figcaption>(a) Nearest, Sample Rate = 1.</figcaption>
		      </td>
		      <td style="text-align: center;">
		        <img src="pics/task5_nearest_sr16.png" width="400px"/>
		        <figcaption>(b) Nearest, Sample Rate = 16.</figcaption>
		      </td>
		    </tr>
		    <tr>
		      <td style="text-align: center;">
		        <img src="pics/task5_bilinear_sr1.png" width="400px"/>
		        <figcaption>(c) Bilinear, Sample Rate = 1.</figcaption>
		      </td>
		      <td style="text-align: center;">
		        <img src="pics/task5_bilinear_sr16.png" width="400px"/>
		        <figcaption>(d) Bilinear, Sample Rate = 16.</figcaption>
		      </td>
		    </tr>
		  </table>
		</div>

		<h2>Task 6: "Level Sampling" with mipmaps for texture mapping</h2>
		In this task, we implement mipmapping and level sampling. The main idea is to preprocess the texture into a multi-level pyramid (level 0 is the original image, level 1 is downsampled by 2, and so on). During rendering, we estimate how much the texture coordinates change per screen pixel; that rate of change determines which mip level should be used. Compared to Task 5, the pixel sampling logic (nearest vs bilinear within a level) remains the same, but we additionally select the appropriate level before sampling. Following the spec, we compute the barycentric texture coordinates for three screen-space positions: <code>(x, y)</code>, <code>(x+1, y)</code>, and <code>(x, y+1)</code>. These three UVs become <code>sp.p_uv</code>, <code>sp.p_dx_uv</code>, and <code>sp.p_dy_uv</code>, respectively. In <code>texture.cpp</code>, <code>get_level(sp)</code> uses the differences <code>(sp.p_dx_uv - sp.p_uv)</code> and <code>(sp.p_dy_uv - sp.p_uv)</code>, scaled by texture resolution, and then take the maximum L2 norm of these two differential vectors and compute a clamped <code>log2</code> to obtain the mip level. We support three level-sampling strategies:
		<ul>
		  <li><b>L_ZERO</b>: always sample from mip level 0 (equivalent to Task 5 behavior).</li>
		  <li><b>L_NEAREST</b>: sample from the nearest integer mip level returned by <code>get_level</code>.</li>
		  <li><b>L_LINEAR</b>: sample from the two neighboring mip levels and linearly interpolate between them.</li>
		</ul>


		With level sampling, we now have three level-sampling strategies, two pixel-sampling strategies, and multiple supersampling settings. Each technique trades compute/memory for improved antialiasing:
		<ul>
		  <li><b>Supersampling</b> increases both computation and sample-buffer storage by a factor of <code>sample_rate</code>.</li>
		  <li><b>Bilinear pixel sampling</b> costs ~4 texel fetches per sample (vs 1 for nearest).</li>
		  <li><b>Mipmapping</b> increases texture storage by less than 2× overall (since <code>1 + 1/4 + 1/16 + ... &lt; 2</code>) and adds extra work to estimate the mip level (computing UV at <code>x+1</code> and <code>y+1</code>).</li>
		  <li><b>L_LINEAR</b> (level interpolation) requires sampling from two mip levels and interpolating between them. Therefore, it can be 2x the compute compared to L_NEAREST</li>
		</ul>


		We use an NYC skycrapers as an example image as it contains a lot of high-frequency textures and thus can easily show the differnces between different methods. As shown below, using a non-zero level-sampling strategy improves visual quality, and bilinear pixel sampling further smooths the results. The zoomed-in region highlights the building window area: combining mipmapping with bilinear sampling produces cleaner and more stable edges, while using only one technique yields intermediate quality. The worst case is sampling directly from level 0 without additional antialiasing techniques.

		<div style="display: flex; flex-direction: column; align-items: center;">
		  <table style="width: 100%; text-align: center; border-collapse: collapse;">
		    <tr>
		      <td style="text-align: center;">
		        <img src="pics/task6_l_0_p_nearest.png" width="400px"/>
		        <figcaption>(a) L_ZERO + P_NEAREST</figcaption>
		      </td>
		      <td style="text-align: center;">
		        <img src="pics/task6_l_0_p_linear.png" width="400px"/>
		        <figcaption>(b) L_ZERO + P_LINEAR</figcaption>
		      </td>
		    </tr>
		    <tr>
		      <td style="text-align: center;">
		        <img src="pics/task6_l_nearest_p_nearest.png" width="400px"/>
		        <figcaption>(c) L_NEAREST + P_NEAREST</figcaption>
		      </td>
		      <td style="text-align: center;">
		        <img src="pics/task6_l_nearest_p_linear.png" width="400px"/>
		        <figcaption>(d) L_NEAREST + P_LINEAR</figcaption>
		      </td>
		    </tr>
		  </table>
		</div>

		<h2>Additional Notes: LLM Disclosure</h2>
		We used Cursor IDE during development, so autocomplete was occasionally applied. We also used an LLM to refine the wording in this write-up. However, the student completed the homework independently without using prior homework solutions or online resources. The student is responsible for all submitted code and write-up content.
		</div>
	</body>
</html>